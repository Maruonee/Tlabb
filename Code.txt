#################################PytorchClass
#install
conda create -n TorchClass
conda activate TorchClass
conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch
pip install matplotlib

#activate
conda activate TorchClass
cd /home/tlab/Tlab/pytorch/Classification

#train
python3 alexnet.py

#detect


##############################TensorEnv
#install
conda create -n TensorEnv python=3.8
conda activate TensorEnv
pip install --upgrade tensorflow
conda install -c anaconda cudnn==8.2.1
pip install opencv-python
pip install matplotlib
pip install SciPy
pip install knockknock

#activate
conda activate TensorEnv

python3 DenseNet201.py ; python3 InceptionResNetV2.py ; python3 InceptionV3.py ; python3 NASNetLarge.py ; python3 RegNetY320.py ; python3 ResNet50.py ; python3 ResNet50V2.py ; python3 ResNetRS50.py ; python3 VGG16.py ; python3 VGG19.py ; python3 Xception.py

python DenseNet201.py & python InceptionResNetV2.py & python InceptionV3.py & python NASNetLarge.py & python RegNetY320.py & python ResNet50.py & python ResNet50V2.py & python ResNetRS50.py & python VGG16.py & python VGG19.py & python Xception.py

##########################################voc2coco
#activate
conda activate ConVformat
cd /home/tlab/Tlab/voc2coco

python3 voc2coco.py --ann_dir /media/tlab/Data/Dataset/Mask/coco/VOC2007/Annotations --ann_ids /media/tlab/Data/Dataset/Mask/coco/VOC2007/ImageSets/Main/val.txt --labels /media/tlab/Data/Dataset/Mask/classes.txt --output /media/tlab/Data/Dataset/Mask/coco/VOC2007/output.json --ext xml

#########################################yolo2COCO
#install 
conda create -n ConVformat python=3.8
conda activate ConVformat
pip install numpy
pip install opencv-python
pip install tqdm
cd /home/tlab/Tlab/yolo2coco
git clone https://github.com/Taeyoung96/Yolo-to-COCO-format-converter.git

#activate
conda activate ConVformat
cd /home/tlab/Tlabb/editdata/yolo2coco
python main.py --path /home/tlab/Tlabb/editdata/yolo2coco/tutorial/test --output test.json


##########################################SplitFolders
conda activate ConVformat
pip install split-folder


#########################################YOLOV3
#install 
conda create -n YOLOV3 python=3.8
conda activate YOLOV3
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
pip install -r requirements.txt
pip install wandb

#activate
conda activate YOLOV3
cd /home/tlab/Tlabb/ObjectDetection/YOLOV3

#Pre train(optimizer hyperparameter)
python train.py --cfg /home/tlab/dataset/opt/yolov3.yaml --data /home/tlab/dataset/opt/cocolabe128.yaml --weights yolov3.pt --batch 32 --epochs 10 --cache --evolve --img 512

#Train 
python train.py --cfg /home/tlab/dataset/opt/yolov3.yaml --data /home/tlab/dataset/opt/coco128.yaml --weights yolov3.pt --batch 32 --epochs 500 --hyp /home/tlab/dataset/opt/v3/hyp_evolve.yaml --img 512

#detect
python detect.py --weights '/home/tlab/dataset/test/weight/YOLOV3/best.pt' --source '/home/tlab/test/nonpass/*.tif' --save-conf --save-txt --conf-thres 0.45 --name 'bestnonpass_045' --save-crop

##########################################YOLOv4
#install 

#activate

#transform data

#Train 

#detec

##########################################YOLOv5
#install 
conda create -n YOLOV5 python=3.8
conda activate YOLOV5
pip install wandb
pip install wandb --upgrade
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
cd /home/tlab/Tlabb/ObjectDetection/YOLOV5
pip install -r requirements.txt

#activate
conda activate YOLOV5
cd /home/tlab/Tlabb/ObjectDetection/YOLOV5

#Pre train(optimizer hyperparameter)
python train.py --cfg /home/tlab/dataset/opt/yolov5x.yaml --data /home/tlab/dataset/opt/coco128.yaml --weights yolov5x.pt --batch 32 --epochs 10 --cache --evolve --img 512

#Train 
python train.py --cfg /home/tlab/dataset/opt/yolov5x.yaml --data /home/tlab/dataset/opt/coco128.yaml --weights best.pt --batch 32 --epochs 500 --hyp /home/tlab/dataset/opt/hyp_evolve.yaml --img 512

#detect
python detect.py --weights best.pt --source '/home/tlab/dataset/IRB/*.tif' --save-conf --save-txt --conf-thres 0.25 --name irb --save-crop

########################################YOLO_X
#install	
conda create -n YOLOXX python=3.8
conda activate YOLOXX
pip install -U pip
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
pip install numpy opencv_python loguru tqdm thop ninja tabulate onnx==1.8.1 onnxruntime==1.8.0 onnx-simplifier==0.3.5
pip install -v -e .

#activate 
conda activate YOLOXX
cd /home/tlab/Tlabb/ObjectDetection/YOLOX

#transform data
/home/tlab/Tlabb/ObjectDetection/YOLOX/datasets/VOCdevkit폴더에 xml파일과 그림파일 한번에 넣기
python voc_txt.py "/home/tlab/Tlabb/ObjectDetection/YOLOX/datasets/VOCdevkit/"
#아래파일 Class 수정
1. yolox/data/datasets/voc_classes.py
2. yolox/data/datasets/coco_classes.py
3. yolox/data/datasets/yolox_voc_s.py 의  self.num_classes를 클래스 수로 수정

#train
python tools/train.py --exp_file //home/tlab/Tlabb/ObjectDetection/YOLOX/exps/example/yolox_voc/yolox_voc_s.py --devices 1 --batch-size 32 --fp16 --occupy --weights yolox_m.pth --cache
epoch수정은 yolox/exp/yolox_base.py의 self.max_epoch에서 설정

#detect
python tools/demo.py --type video[image] --weights yolox_s.pth --path /home/tlab/Tlabb/ObjectDetection/YOLOR/data/video/sample.mp4 --conf 0.25 --nms 0.45 --img-size 640 --save_result --device gpu --name yolox-s 

#test
python tools/eval.py --exp_file /home/tlab/dataset/opt/yolox_voc_s.py --weights best_ckpt.pth --batch-size 64 -- devices 1 --conf 0.001 --fp16 --name yolox-s --img-size 640 --name yolox-s

########################################YOLOR
#install	
conda create -n YOLORR python=3.8
conda activate YOLORR
cd /home/tlab/Tlabb/ObjectDetection/YOLOR
pip install seaborn thop
pip install cython
pip install "git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI"
pip install opencv-contrib-python
pip install -r requirements-gpu.txt
conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 cudatoolkit=11.3 -c pytorch

#activate 
conda activate YOLORR
cd /home/tlab/Tlabb/ObjectDetection/YOLOR

#cfg
batch size = 64, subdivision = 16 training image at a time 4
yolo 부분에 있는 classes yolo위쪽에 있는 filter = 3 * (5 + classes)
max_batches = class * 2000
steps는 max_batches의 80%의 수치와 90%의 수치
filter: 3 * (5 + classes) = 255
#L1569, #L1573, #L1577, #L1581, #L1605, #L1649, #L1693, #L1737

#Pre train(optimizer hyperparameter)
python train.py --batch-size 32 --img 512 512 --data /home/tlab/dataset/opt/coco.yaml --cfg /home/tlab/dataset/opt/yolor_p6.cfg --weights  yolor_p6.pt --device 0 --epochs 10 --evolve --cache --workers 16

#train
python train.py --batch-size 32 --img 512 512 --data /home/tlab/dataset/opt/coco.yaml --cfg /home/tlab/dataset/opt/yolor_p6.cfg --weights  yolor_p6.pt --device 0 --epochs 500 --hyp /home/tlab/dataset/opt/R/hyp_evolved.yaml --cache --workers 16

#detect
python detect.py --source /home/tlab/Tlabb/ObjectDetection/YOLOR/data/video/sample.mp4 --cfg cfg/yolor_p6.cfg --weights yolor_p6.pt --conf-thres 0.25 --img-size 1280 --device 0 --save-txt --iou-thres 0.5

#test
python test.py --data data/coco.yaml --img-size 1280 --batch-size 32 --conf-thres 0.001 --iou-thres 0.65 --device 0 --cfg cfg/yolor_p6.cfg --weights yolor_p6.pt --name yolor_p6_val --verbose --save-txt --save-conf
########################################YOLOV6
#install
conda create -n YOLOV66 python=3.8
conda activate YOLOV66
cd /home/tlab/Tlabb/ObjectDetection/YOLOV6
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
pip install numpy opencv-python PyYAML scipy tqdm addict tensorboard pycocotools onnx onnx-simplifier thop

#activate 
conda activate YOLOV66
cd /home/tlab/Tlabb/ObjectDetection/YOLOV6

#custom_dataset
├── images
│   ├── train
│   │   ├── train0.jpg
│   │   └── train1.jpg
│   ├── val
│   │   ├── val0.jpg
│   │   └── val1.jpg
│   └── test
│       ├── test0.jpg
│       └── test1.jpg
└── labels
    ├── train
    │   ├── train0.txt
    │   └── train1.txt
    ├── val
    │   ├── val0.txt
    │   └── val1.txt
    └── test
        ├── test0.txt
        └── test1.txt
        
#train
python tools/train.py --batch-size 32 --conf-file configs/yolov6n.py --data-path /home/tlab/dataset/opt/yolov6.yaml --device 0 --img-size 512 --epochs 500 --workers 16

#Test
python tools/eval.py --data data/coco.yaml --batch 32 --weights yolov6s.pt --task val

#detect
python tools/infer.py --weights yolov6s.pt --source /home/tlab/Tlabb/ObjectDetection/YOLOV6/data/images

########################################YOLOV7
#install
conda create -n YOLOV7 python=3.8
conda activate YOLOV7
cd /home/tlab/Tlabb/ObjectDetection/YOLOV7
conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch
pip install -r requirements.txt

#activate 
conda activate YOLOV7
cd /home/tlab/Tlabb/ObjectDetection/YOLOV7

#Pre train(optimizer hyperparameter)
python train.py --workers 16 --img 512 --cfg /home/tlab/dataset/opt/yolov7.yaml --data /home/tlab/dataset/opt/coco.yaml --weights yolov7.pt --batch-size 32 --epochs 10 --evolve

#train
python train.py --workers 16 --img 512 512 --cfg /home/tlab/dataset/opt/yolov7.yaml --data /home/tlab/dataset/opt/coco.yaml --weights yolov7.pt --batch-size 32 --epochs 500

#Test
python test.py --data data/coco.yaml --img 640 --batch 32 --conf 0.001 --iou 0.65 --weights yolov7.pt --name yolov7_640_val

#detect
python detect.py --weights yolov7.pt --source '/home/tlab/test/nonpass/*.tif' --save-conf --save-txt --conf-thres 0.4 --name 'lastnonpass_04' --line-thickness 5

#Pose Training
cd /home/tlab/Tlabb/ObjectDetection/YOLOV7_P
python train.py --data data/coco_kpts.yaml --cfg cfg/yolov7-w6-pose.yaml --weights weights/yolov7-w6-person.pt --batch-size 128 --img 960 --kpt-label --sync-bn --device 0 --name yolov7-w6-pose --hyp data/hyp.pose.yaml

#Pose test
python test.py --data data/coco_kpts.yaml --img 960 --conf 0.001 --iou 0.65 --weights yolov7-w6-pose.pt --kpt-label

#Pose detect
python detect.py --weights yolov7-w6-pose.pt --source /home/tlab/Tlabb/ObjectDetection/YOLOV7/figure/yoga8.mp4 --kpt-label --line-thickness 8 --hide-labels --hide-conf --nobbox

===================hand
conda create -n hand python=3.8.8
conda activate hand
pip install mediapipe opencv-python

conda activate hand
cd C:\Users\tiger1005\Documents\Pose
Jupyter Notebook

===================allpose
conda create -n allpose python=3.8.8
conda activate allpose
pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python matplotlib

conda activate allpose
cd C:\Users\tiger1005\Documents\Pose
Jupyter Notebook

===================DETR
conda create -n DETR python=3.8.8
conda activate DETR
conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch

conda activate DETR
cd /home/tlab/Tlabb/ObjectDetection/DETR
path/to/coco/
  annotations/  # annotation json files
  train2017/    # train images
  val2017/      # val images

train
python main.py --coco_path /home/tlab/Tlabb/editdata/yolo2coco/tutorial --epochs 300 --num_workers 16
  
python main.py --coco_path /media/tlab/Data/Dataset/COCO/coco2017 --epochs 1 --num_workers 0 --batch_size 2

Evaluation
python main.py --batch_size 2 --no_aux_loss --eval --resume /home/tlab/Tlabb/ObjectDetection/DETR/runs/train/eval/latest.pth --coco_path /home/tlab/Tlabb/editdata/yolo2coco/tutorial

=========================================================
이름바꾸기
1. 확인
rename -n 's/.jpg/.tif/' *.jpg
rename -n 's/.tif/.jpg/' *.tif
2. 실행
rename -f 's/.jpg/.tif/' *.jpg
rename -f 's/.tif/.jpg/' *.tif
3. 데이터 파일 리스트 만들기
find /home/tlab/Tlabb/editdata/yolo2coco/tutorial/val -name '*.jpg' -type f > val.txt
4. 삭제
conda env remove -n YOLO6
=========================================================
LaTex
texmaker

