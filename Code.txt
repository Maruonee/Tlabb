#########################################dataedit
#install 
conda create -n ConVformat python=3.8
conda activate ConVformat
pip install numpy opencv-python tqdm sklearn split-folder scikit-learn
git clone https://github.com/Taeyoung96/Yolo-to-COCO-format-converter.git

#activate
cd /home/tlab/Tlab/yolo2coco
conda activate ConVformat
cd /home/tlab/Tlabb/editdata/yolo2coco
python main.py --path /home/tlab/Tlabb/editdata/yolo2coco/tutorial/test --output test.json

#activate
cd /home/tlab/Tlab/voc2coco
python3 voc2coco.py --ann_dir /media/tlab/Data/Dataset/Mask/coco/VOC2007/Annotations --ann_ids /media/tlab/Data/Dataset/Mask/coco/VOC2007/ImageSets/Main/val.txt --labels /media/tlab/Data/Dataset/Mask/classes.txt --output /media/tlab/Data/Dataset/Mask/coco/VOC2007/output.json --ext xml

#########################################YOLOV3
#install 
conda create -n YOLOV3 python=3.8
conda activate YOLOV3
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge wandb
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOV3
pip install wandb -r requirements.txt

#activate
conda activate YOLOV3

#Pre train(optimizer hyperparameter)
python train.py --cfg /home/tlab1004/dataset/opt/yolov3.yaml --data /home/tlab1004/dataset/opt/coco128.yaml --weights yolov3.pt --batch 32 --epochs 10 --cache --evolve --img 512

#Train 
python train.py --cfg /home/tlab1004/dataset/opt/yolov3.yaml --data /home/tlab1004/dataset/opt/coco128.yaml --weights yolov3.pt --batch 32 --epochs 500 --img 512


 --hyp /home/tlab1004/dataset/opt/V3/hyp_evolve.yaml --img 512

#detect
python detect.py --weights '/home/tlab/results/gray/v3/weights/best.pt' --source '/home/tlab/testset/*.tif' --save-conf --save-txt --conf-thres 0.4 --name 'con0.40' --save-crop

#eval
python val.py --data /home/tlab1004/dataset/opt/coco128.yaml --weights /home/tlab1004/dataset/data/two/YOLOV3.pt --img 512 --verbose --save-txt --save-hybrid --augment --save-json --exist-ok

##########################################YOLOv5
#install 
conda create -n YOLOV5 python=3.8
conda activate YOLOV5
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOV5
pip install wandb -r requirements.txt
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge

#activate
conda activate YOLOV5
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOV5

#Pre train(optimizer hyperparameter)
python train.py --cfg /home/tlab1004/dataset/opt/yolov5x.yaml --data /home/tlab1004/dataset/opt/coco128.yaml --weights yolov5x.pt --batch 32 --epochs 10 --cache --evolve --img 512

#Train 
python train.py --cfg /home/tlab1004/dataset/opt/yolov5x.yaml --data /home/tlab1004/dataset/opt/coco128.yaml --weights yolov5x.pt --batch 32 --epochs 500 --img 512
 --hyp /home/tlab1004/dataset/opt/V5/hyp_evolve.yaml
 
#detect
python detect.py --weights /home/tlab1004/Tlabb/ObjectDetection/YOLOV5/runs/train/exp/weights/best.pt --source '/home/tlab1004/dataset/images/*.jpg' --save-conf --save-txt --conf-thres 0.5 --save-crop --line-thickness 6

#eval
python val.py --data /home/tlab/dataset/opt/coco128.yaml --weights /home/tlab1004/dataset/data/two/YOLOV5.pt --img 512

python val.py --data /home/tlab1004/dataset/opt/coco128.yaml --weights /home/tlab1004/dataset/data/two/YOLOV3.pt --img 512


########################################YOLO_X
#install	
conda create -n YOLOX python=3.8
conda activate YOLOX
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOX
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
pip install numpy opencv_python loguru tqdm thop ninja tabulate onnx==1.8.1 onnxruntime==1.8.0 onnx-simplifier==0.3.5 tensorboard wandb
pip install -v -e .
python3 setup.py develop
#activate 
conda activate YOLOXX
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOX

#transform data
YOLOX/datasets/VOCdevkit폴더에 xml파일과 그림파일 한번에 넣기
python voc_txt.py "/home/tlab1004/Tlabb/ObjectDetection/YOLOX/datasets/VOCdevkit/"
* rename -f 's/.tif/.jpg/' *.tif
* VOC2007만 사용함
#아래파일 Class 수정(최소 class 4)
1. YOLOX/yolox/data/datasets/voc_classes.py
2. YOLOX/yolox/data/datasets/coco_classes.py
3. opt yolox_voc수정  self.num_classes를 클래스 수로 수정

#train
python tools/train.py -f /home/tlab1004/Tlabb/ObjectDetection/YOLOX/exps/example/yolox_voc/yolox_voc_m.py -d 1 -b 32 --fp16 -o -c yolox_m.pth --cache -l wandb
epoch수정은 yolox/exp/yolox_base.py의 self.max_epoch에서 설정

#detect
python tools/demo.py --type image --weights /home/tlab/results/pene/x/best_ckpt.pth --path  '/home/tlab/testset/*.tif' --conf 0.01 --nms 0.45 --img-size 640 --save_result --device gpu --name yolox-s 

#test
python tools/eval.py --exp_file /home/tlab/Tlabb/ObjectDetection/YOLOX/exps/example/yolox_voc/yolox_voc_s.py --weights /home/tlab/dataset/X/1/best_ckpt.pth --batch-size 32 -- devices 1 --conf 0.25 --fp16 --name yolox-s1 --img-size 512

########################################YOLOR
#install	
conda create -n YOLORR python=3.8
conda activate YOLORR
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOR
pip install seaborn thop cython opencv-contrib-python
conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 cudatoolkit=11.3 -c pytorch
pip install -r requirements.txt

#activate 
conda activate YOLORR
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOR

#cfg 21
batch size = 64, subdivision = 16 training image at a time 4
yolo 부분에 있는 classes yolo위쪽에 있는 filter = 3 * (5 + classes)
max_batches = class * 2000
steps는 max_batches의 80%의 수치와 90%의 수치
filter: 3 * (5 + classes) = 255
#L1569, #L1573, #L1577, #L1581, #L1605, #L1649, #L1693, #L1737

#Pre train(optimizer hyperparameter)
python train.py --batch-size 32 --img 512 512 --data /home/tlab/dataset/opt/coco.yaml --cfg /home/tlab/dataset/opt/yolor_p6.cfg --weights  yolor_p6.pt --device 0 --epochs 10 --evolve --cache

#train
python train.py --batch-size 32 --img 512 512 --data /home/tlab/dataset/opt/coco.yaml --cfg /home/tlab/dataset/opt/yolor_p6.cfg --weights  yolor_p6.pt --device 0 --epochs 500 --cache

#detect
python detect.py --source '/home/tlab/testset/*.tif' --cfg /home/tlab/dataset/opt/yolor_p6.cfg --weights /home/tlab/results/gray/R/weights/best.pt --conf-thres 0.01 --img-size 512 --device 0 --save-txt --iou-thres 0.5

#test
python test.py --data /home/tlab/dataset/opt/coco.yaml --img-size 512 --batch-size 32 --device 0 --cfg /home/tlab/dataset/opt/yolor_p6.cfg --weights /home/tlab/results/r/weights/best.pt --name yolor_1_val --verbose --save-txt --save-conf

########################################YOLOV6
#install
conda create -n YOLOV66 python=3.8
conda activate YOLOV66
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOV6
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
pip install numpy opencv-python PyYAML scipy tqdm addict tensorboard pycocotools onnx onnx-simplifier thop

#activate 
conda activate YOLOV66
cd /home/tlab/Tlabb/ObjectDetection/YOLOV6

#custom_dataset
├── images
│   ├── train
│   │   ├── train0.jpg
│   │   └── train1.jpg
│   ├── val
│   │   ├── val0.jpg
│   │   └── val1.jpg
│   └── test
│       ├── test0.jpg
│       └── test1.jpg
└── labels
    ├── train
    │   ├── train0.txt
    │   └── train1.txt
    ├── val
    │   ├── val0.txt
    │   └── val1.txt
    └── test
        ├── test0.txt
        └── test1.txt
        
#train
python tools/train.py --batch-size 32 --conf-file configs/yolov6l.py --data-path /home/tlab/dataset/opt/dataset.yaml --device 0 --img-size 512 --epochs 500

#Test
python tools/eval.py --data /home/tlab/dataset/opt/dataset.yaml --batch-size 32 --weights /home/tlab/results/v6/weights/best_ckpt.pt --img-size 512 --verbose --name yolor_1_val

#detect
python tools/infer.py --weights /home/tlab/results/gray/V6/weights/best_ckpt.pt --source '/home/tlab/testset/' --conf-thres 0.5 --yaml /home/tlab/dataset/opt/dataset.yaml --iou-thres 0.5

########################################YOLOV7
#install
conda create -n YOLOV77 python=3.8
conda activate YOLOV77
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOV7
conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge
pip install -r requirements.txt
pip install wandb

#activate 
conda activate YOLOV77
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOV7

#Pre train(optimizer hyperparameter)
python train.py --cfg /home/tlab1004/dataset/opt/yolov7x.yaml --data /home/tlab1004/dataset/opt/coco.yaml --weights yolov7x.pt --batch 32 --epochs 10 --img 512 --device 0  --evolve

#train
python train.py --cfg /home/tlab1004/dataset/opt/yolov7x.yaml --data /home/tlab1004/dataset/opt/coco.yaml --weights yolov7x.pt --batch 32 --epochs 500 --img 512 --device 0
 --hyp /home/tlab1004/dataset/opt/V7/hyp_evolved.yaml
 
#Test
python test.py --data /home/tlab/dataset/opt/coco.yaml --img 512 --batch 32 --weights /home/tlab/results/v7/weights/best.pt

#detect
python detect.py --weights '/home/tlab1004/Tlabb/ObjectDetection/YOLOV7/runs/train/exp3/weights/best.pt' --source '/home/tlab1004/dataset/images/*.jpg' --save-conf --save-txt --conf-thres 0.1 --device 0

#Pose Training
cd /home/tlab1004/Tlabb/ObjectDetection/YOLOV7_P
python train.py --data data/coco_kpts.yaml --cfg cfg/yolov7-w6-pose.yaml --weights weights/yolov7-w6-person.pt --batch-size 128 --img 960 --kpt-label --sync-bn --device 0 --name yolov7-w6-pose --hyp data/hyp.pose.yaml

#Pose test
python test.py --data data/coco_kpts.yaml --img 960 --conf 0.001 --iou 0.65 --weights yolov7-w6-pose.pt --kpt-label

#Pose detect
python detect.py --weights yolov7-w6-pose.pt --source /home/tlab1004/Tlabb/ObjectDetection/YOLOV7_P/data/IMG_0413.MP4 --kpt-label --line-thickness 8 --hide-labels --hide-conf --nobbox

########################################Alphapose
cd /home/tlab1004/Tlabb/Pose/AlphaPose
conda create -n ahpose python=3.7 -y
conda activate ahpose
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
export PATH=/usr/local/cuda/bin/:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64/:$LD_LIBRARY_PATH
python -m pip install cython
pip install opencv-python matplotlib tqdm natsort scipy cython_bbox easydict pyyaml pycocotools

sudo apt-get install libyaml-dev
python setup.py build develop

#detect
python scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res152_lr1e-3_1x-duc.yaml --checkpoint pretrained_models/fast_421_res152_256x192.pth --indir /home/tlab1004/dataset/ChestPA/raw/train/Pass/ --outdir runs/exp --save_img --detector yolo --showbox --vis_fast
########################################mmpose
cd /home/tlab1004/Tlabb/Pose/mmpose
conda create --name openmmlab python=3.8 -y
conda activate openmmlab
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
pip install -U openmim
mim install mmcv-full
pip install -r requirements.txt
pip install -v -e .

python demo/top_down_img_demo_with_mmdet.py \
    demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \
    https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \
    configs/wholebody/2d_kpt_sview_rgb_img/topdown_heatmap/coco-wholebody/hrnet_w48_coco_wholebody_384x288_dark_plus.py \
    https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth \
    --img-root /home/tlab1004/dataset/rawclass/Fail/ \
    --out-img-root runs/exp

python demo/bottom_up_img_demo.py \
    configs/body/2d_kpt_sview_rgb_img/associative_embedding/coco/hrnet_w32_coco_512x512.py \
    https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth \
    --img-path /home/tlab1004/dataset/ChestPA/raw/train/Pass/ \
    --out-img-root runs/exp --radius 10 --thickness 10
    
configs/body/2d_kpt_sview_rgb_img/associative_embedding/aic/hrnet_w32_aic_512x512.py
===================hand
conda create -n hand python=3.8.8
conda activate hand
pip install mediapipe opencv-python

conda activate hand
cd C:\Users\tiger1005\Documents\Pose
Jupyter Notebook

===================allpose
conda create -n allpose python=3.8.8
conda activate allpose
pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python matplotlib

conda activate allpose
cd C:\Users\tiger1005\Documents\Pose
Jupyter Notebook

===================DETR
conda create -n DETR python=3.8.8
conda activate DETR
conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch

conda activate DETR
cd /home/tlab/Tlabb/ObjectDetection/DETR
path/to/coco/
  annotations/  # annotation json files
  train2017/    # train images
  val2017/      # val images

train
python main.py --coco_path /home/tlab/Tlabb/editdata/yolo2coco/tutorial --epochs 300 --num_workers 16
  
python main.py --coco_path /media/tlab/Data/Dataset/COCO/coco2017 --epochs 1 --num_workers 0 --batch_size 2

Evaluation
python main.py --batch_size 2 --no_aux_loss --eval --resume /home/tlab/Tlabb/ObjectDetection/DETR/runs/train/eval/latest.pth --coco_path /home/tlab/Tlabb/editdata/yolo2coco/tutorial

=========================================================
이름바꾸기
1. 확인
rename -n 's/.txt/.docx/' *.txt
rename -n 's/.docx/.txt/' *.docx
rename -n 's/.tif/.jpg/' *.tif
2. 실행
rename -f 's/.jpg/.tif/' *.jpg
rename 's/.docx/.txt/' *.docx

find . -type f -name "*.doc" -exec rename .doc .txt {} \;


3. 데이터 파일 리스트 만들기
find /home/tlab/Tlabb/editdata/yolo2coco/tutorial/val -name '*.jpg' -type f > val.txt
4. 삭제
conda env remove -n alphapose
=========================================================
LaTex
texmaker

sudo apt-get install xmacro
xmacrorec2 > test.file
for (( i=0; i<100; i++ )); do   xmacroplay "$DISPLAY" <test.file; done



pip install tensorboard
tensorboard --logdir = /home/tlab/log
